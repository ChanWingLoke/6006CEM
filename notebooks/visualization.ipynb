{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "832fce7a",
   "metadata": {},
   "source": [
    "\n",
    "# Visualization — RF (Traditional) & MLP (Deep Learning)\n",
    "\n",
    "This notebook visualizes results from your two-model setup:\n",
    "- **Random Forest Regressor** (traditional ML)\n",
    "- **MLP Regressor** (deep learning)\n",
    "\n",
    "It will:\n",
    "1. Load the metrics table and plot **R² (log), MAE ($), RMSE ($)** across *validation* and *test*.\n",
    "2. Show **feature importances** for Random Forest (tree-based importance).\n",
    "3. (Optional) Compute **Permutation Importance** for MLP on the test set (since MLP has no built-in importances).\n",
    "4. Plot **Predicted vs Actual** and **Residuals vs Predicted** on the test set, using the best available model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import sparse\n",
    "import joblib\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (9, 5)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "RESULTS_DIR = Path('../results')\n",
    "METRICS_CSV = RESULTS_DIR / 'metrics_comparison.csv'\n",
    "FEATURE_RF = RESULTS_DIR / 'feature_importance_rf.csv'\n",
    "FEATURE_NAMES_JSON = RESULTS_DIR / 'feature_names.json'\n",
    "\n",
    "def load_matrix(path: Path):\n",
    "    path = Path(path)\n",
    "    candidates = []\n",
    "    if path.suffix:\n",
    "        candidates.append(path)\n",
    "    candidates.extend([path.with_suffix('.npz'), path.with_suffix('.npy')])\n",
    "    for p in candidates:\n",
    "        if not p.exists():\n",
    "            continue\n",
    "        try:\n",
    "            return sparse.load_npz(p)\n",
    "        except Exception:\n",
    "            try:\n",
    "                return np.load(p, allow_pickle=False)\n",
    "            except Exception:\n",
    "                pass\n",
    "    raise FileNotFoundError(f'Could not load matrix for {path} (tried .npz and .npy).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc4f0d",
   "metadata": {},
   "source": [
    "## 1) Metrics overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = pd.read_csv(METRICS_CSV)\n",
    "display(metrics)\n",
    "\n",
    "required_cols = {'Model', 'Split', 'R2_log', 'MAE_raw', 'RMSE_raw'}\n",
    "missing = required_cols - set(metrics.columns)\n",
    "if missing:\n",
    "    raise ValueError(f'metrics_comparison.csv missing columns: {missing}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e1fdfd",
   "metadata": {},
   "source": [
    "## 2) Bar charts — Validation & Test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6833d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_metric(df: pd.DataFrame, metric: str, title: str):\n",
    "    pivot = df.pivot(index='Model', columns='Split', values=metric)\n",
    "    ax = pivot.plot(kind='bar', rot=0, figsize=(9,5), title=title)\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel(metric)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_metric(metrics, 'R2_log', 'R² (log target) — by Model & Split')\n",
    "plot_metric(metrics, 'MAE_raw', 'MAE ($, raw target) — by Model & Split')\n",
    "plot_metric(metrics, 'RMSE_raw', 'RMSE ($, raw target) — by Model & Split')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825a8a98",
   "metadata": {},
   "source": [
    "## 3) Feature importances — Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1216e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if FEATURE_RF.exists():\n",
    "    imp_rf = pd.read_csv(FEATURE_RF).sort_values('importance', ascending=False)\n",
    "    top = imp_rf.head(20).iloc[::-1]\n",
    "    ax = top.plot(kind='barh', x='feature', y='importance', legend=False, figsize=(9,7), title='Random Forest — Top 20 Features')\n",
    "    ax.set_xlabel('importance')\n",
    "    ax.set_ylabel('feature')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('[skip] feature_importance_rf.csv not found — train RandomForest first.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5a94e6",
   "metadata": {},
   "source": [
    "## 4) (Optional) Permutation Importance — MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f944373",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = load_matrix(RESULTS_DIR / 'X_test')\n",
    "y_test_log = np.load(RESULTS_DIR / 'y_test_log.npy')\n",
    "y_test_raw = np.load(RESULTS_DIR / 'y_test_raw.npy')\n",
    "\n",
    "feature_names = []\n",
    "if FEATURE_NAMES_JSON.exists():\n",
    "    import json\n",
    "    feature_names = json.loads(FEATURE_NAMES_JSON.read_text())\n",
    "\n",
    "mlp_paths = [RESULTS_DIR / 'model_mlp_tuned.joblib', RESULTS_DIR / 'model_mlp.joblib']\n",
    "mlp_model = None\n",
    "mlp_name = None\n",
    "for p in mlp_paths:\n",
    "    if p.exists():\n",
    "        mlp_model = joblib.load(p)\n",
    "        mlp_name = p.name\n",
    "        break\n",
    "\n",
    "if mlp_model is None:\n",
    "    print('[skip] No MLP model found; skipping permutation importance.')\n",
    "else:\n",
    "    if sparse.issparse(X_test):\n",
    "        X_for_mlp = X_test.toarray()\n",
    "    else:\n",
    "        X_for_mlp = X_test\n",
    "\n",
    "    n = X_for_mlp.shape[0]\n",
    "    idx = np.arange(n)\n",
    "    if n > 2000:\n",
    "        rng = np.random.default_rng(42)\n",
    "        idx = rng.choice(idx, size=2000, replace=False)\n",
    "        X_for_mlp = X_for_mlp[idx]\n",
    "        y_for_mlp = y_test_log[idx]\n",
    "    else:\n",
    "        y_for_mlp = y_test_log\n",
    "\n",
    "    print(f'Computing permutation importance for {mlp_name} on {X_for_mlp.shape[0]} samples...')\n",
    "    result = permutation_importance(\n",
    "        mlp_model, X_for_mlp, y_for_mlp,\n",
    "        scoring='r2', n_repeats=5, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    importances = pd.DataFrame({\n",
    "        'feature': feature_names[:len(result.importances_mean)] if feature_names else np.arange(len(result.importances_mean)),\n",
    "        'importance': result.importances_mean\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    top_mlp = importances.head(20).iloc[::-1]\n",
    "    ax = top_mlp.plot(kind='barh', x='feature', y='importance', legend=False, figsize=(9,7), title='MLP Permutation Importance — Top 20 (ΔR²)')\n",
    "    ax.set_xlabel('importance (mean ΔR² when permuted)')\n",
    "    ax.set_ylabel('feature')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d3a064",
   "metadata": {},
   "source": [
    "## 5) Residual analysis on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ac553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_paths_ordered = [\n",
    "    RESULTS_DIR / 'model_mlp_tuned.joblib',\n",
    "    RESULTS_DIR / 'model_mlp.joblib',\n",
    "    RESULTS_DIR / 'model_rf_tuned.joblib',\n",
    "    RESULTS_DIR / 'model_rf.joblib',\n",
    "]\n",
    "\n",
    "model = None\n",
    "chosen = None\n",
    "for p in model_paths_ordered:\n",
    "    if p.exists():\n",
    "        model = joblib.load(p)\n",
    "        chosen = p.name\n",
    "        break\n",
    "\n",
    "if model is None:\n",
    "    raise FileNotFoundError('No trained model found. Run train_models.py first.')\n",
    "\n",
    "def to_dense(X):\n",
    "    if sparse.issparse(X):\n",
    "        return X.toarray()\n",
    "    return X\n",
    "\n",
    "y_pred_log = model.predict(to_dense(X_test))\n",
    "y_pred_raw = np.expm1(y_pred_log)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_test_raw, y_pred_raw, s=12)\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title(f'Predicted vs Actual — Test (model: {chosen})')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "residuals = y_test_raw - y_pred_raw\n",
    "plt.figure()\n",
    "plt.scatter(y_pred_raw, residuals, s=12)\n",
    "plt.axhline(0, linestyle='--')\n",
    "plt.xlabel('Predicted SalePrice')\n",
    "plt.ylabel('Residual (Actual - Predicted)')\n",
    "plt.title(f'Residuals vs Predicted — Test (model: {chosen})')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "pd.Series(residuals).describe().to_frame('Residuals Summary')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}